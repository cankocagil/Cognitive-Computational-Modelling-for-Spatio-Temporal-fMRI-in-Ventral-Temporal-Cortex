{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                        - Computational Neuroscience 2021-2022 Final Project -        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   Project Name: Combinatorial Codes in Ventral Temporal Lobe for Visual Object Recognition\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: umap in d:\\python\\lib\\site-packages (0.1.1)\n",
      "Requirement already satisfied: pipreqs in d:\\python\\lib\\site-packages (0.4.10)\n",
      "Requirement already satisfied: yarg in d:\\python\\lib\\site-packages (from pipreqs) (0.1.9)\n",
      "Requirement already satisfied: docopt in d:\\python\\lib\\site-packages (from pipreqs) (0.6.2)\n",
      "Requirement already satisfied: requests in d:\\python\\lib\\site-packages (from yarg->pipreqs) (2.24.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\python\\lib\\site-packages (from requests->yarg->pipreqs) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\python\\lib\\site-packages (from requests->yarg->pipreqs) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in d:\\python\\lib\\site-packages (from requests->yarg->pipreqs) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in d:\\python\\lib\\site-packages (from requests->yarg->pipreqs) (3.0.4)\n",
      "Requirement already satisfied: lazypredict in d:\\python\\lib\\site-packages (0.2.9)\n",
      "Requirement already satisfied: scipy==1.5.4 in d:\\python\\lib\\site-packages (from lazypredict) (1.5.4)\n",
      "Requirement already satisfied: joblib==1.0.0 in d:\\python\\lib\\site-packages (from lazypredict) (1.0.0)\n",
      "Requirement already satisfied: PyYAML==5.3.1 in d:\\python\\lib\\site-packages (from lazypredict) (5.3.1)\n",
      "Requirement already satisfied: pandas==1.0.5 in d:\\python\\lib\\site-packages (from lazypredict) (1.0.5)\n",
      "Requirement already satisfied: click==7.1.2 in d:\\python\\lib\\site-packages (from lazypredict) (7.1.2)\n",
      "Requirement already satisfied: scikit-learn==0.23.1 in d:\\python\\lib\\site-packages (from lazypredict) (0.23.1)\n",
      "Requirement already satisfied: lightgbm==2.3.1 in d:\\python\\lib\\site-packages (from lazypredict) (2.3.1)\n",
      "Requirement already satisfied: xgboost==1.1.1 in d:\\python\\lib\\site-packages (from lazypredict) (1.1.1)\n",
      "Requirement already satisfied: numpy==1.19.1 in d:\\python\\lib\\site-packages (from lazypredict) (1.19.1)\n",
      "Requirement already satisfied: pytest==5.4.3 in d:\\python\\lib\\site-packages (from lazypredict) (5.4.3)\n",
      "Requirement already satisfied: six==1.15.0 in d:\\python\\lib\\site-packages (from lazypredict) (1.15.0)\n",
      "Requirement already satisfied: tqdm==4.56.0 in d:\\python\\lib\\site-packages (from lazypredict) (4.56.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in d:\\python\\lib\\site-packages (from pandas==1.0.5->lazypredict) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in d:\\python\\lib\\site-packages (from pandas==1.0.5->lazypredict) (2.8.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\python\\lib\\site-packages (from scikit-learn==0.23.1->lazypredict) (2.1.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in d:\\python\\lib\\site-packages (from pytest==5.4.3->lazypredict) (8.6.0)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in d:\\python\\lib\\site-packages (from pytest==5.4.3->lazypredict) (0.4.4)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in d:\\python\\lib\\site-packages (from pytest==5.4.3->lazypredict) (0.13.1)\n",
      "Requirement already satisfied: packaging in d:\\python\\lib\\site-packages (from pytest==5.4.3->lazypredict) (20.4)\n",
      "Requirement already satisfied: py>=1.5.0 in d:\\python\\lib\\site-packages (from pytest==5.4.3->lazypredict) (1.9.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0; sys_platform == \"win32\" in d:\\python\\lib\\site-packages (from pytest==5.4.3->lazypredict) (1.4.0)\n",
      "Requirement already satisfied: wcwidth in d:\\python\\lib\\site-packages (from pytest==5.4.3->lazypredict) (0.2.5)\n",
      "Requirement already satisfied: attrs>=17.4.0 in d:\\python\\lib\\site-packages (from pytest==5.4.3->lazypredict) (20.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in d:\\python\\lib\\site-packages (from packaging->pytest==5.4.3->lazypredict) (2.4.7)\n",
      "Requirement already satisfied: nibabel in d:\\python\\lib\\site-packages (3.2.1)\n",
      "Requirement already satisfied: numpy>=1.14 in d:\\python\\lib\\site-packages (from nibabel) (1.19.1)\n",
      "Requirement already satisfied: packaging>=14.3 in d:\\python\\lib\\site-packages (from nibabel) (20.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in d:\\python\\lib\\site-packages (from packaging>=14.3->nibabel) (2.4.7)\n",
      "Requirement already satisfied: six in d:\\python\\lib\\site-packages (from packaging>=14.3->nibabel) (1.15.0)\n",
      "Requirement already satisfied: nilearn in d:\\python\\lib\\site-packages (0.7.1)\n",
      "Requirement already satisfied: scipy>=0.19 in d:\\python\\lib\\site-packages (from nilearn) (1.5.4)\n",
      "Requirement already satisfied: pandas>=0.18.0 in d:\\python\\lib\\site-packages (from nilearn) (1.0.5)\n",
      "Requirement already satisfied: scikit-learn>=0.19 in d:\\python\\lib\\site-packages (from nilearn) (0.23.1)\n",
      "Requirement already satisfied: nibabel>=2.0.2 in d:\\python\\lib\\site-packages (from nilearn) (3.2.1)\n",
      "Requirement already satisfied: joblib>=0.12 in d:\\python\\lib\\site-packages (from nilearn) (1.0.0)\n",
      "Requirement already satisfied: requests>=2 in d:\\python\\lib\\site-packages (from nilearn) (2.24.0)\n",
      "Requirement already satisfied: numpy>=1.11 in d:\\python\\lib\\site-packages (from nilearn) (1.19.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in d:\\python\\lib\\site-packages (from pandas>=0.18.0->nilearn) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in d:\\python\\lib\\site-packages (from pandas>=0.18.0->nilearn) (2020.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\python\\lib\\site-packages (from scikit-learn>=0.19->nilearn) (2.1.0)\n",
      "Requirement already satisfied: packaging>=14.3 in d:\\python\\lib\\site-packages (from nibabel>=2.0.2->nilearn) (20.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\python\\lib\\site-packages (from requests>=2->nilearn) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in d:\\python\\lib\\site-packages (from requests>=2->nilearn) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\python\\lib\\site-packages (from requests>=2->nilearn) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in d:\\python\\lib\\site-packages (from requests>=2->nilearn) (3.0.4)\n",
      "Requirement already satisfied: six>=1.5 in d:\\python\\lib\\site-packages (from python-dateutil>=2.6.1->pandas>=0.18.0->nilearn) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in d:\\python\\lib\\site-packages (from packaging>=14.3->nibabel>=2.0.2->nilearn) (2.4.7)\n",
      "Requirement already up-to-date: kaleido in d:\\python\\lib\\site-packages (0.2.1)\n",
      "Scikit-learn is available, version 0.23.1\n",
      "Open-CV is available, version 4.5.1\n",
      "Seaborn is available, version 0.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install umap\n",
    "!pip install pipreqs\n",
    "!pip install lazypredict\n",
    "!pip install nibabel\n",
    "!pip install nilearn\n",
    "!pip install -U kaleido\n",
    "\n",
    "\n",
    "try:\n",
    "    import sklearn\n",
    "    print('Scikit-learn is available, version', sklearn.__version__)\n",
    "    \n",
    "except:\n",
    "    !pip install scikit-learn\n",
    "    \n",
    " \n",
    "try:\n",
    "    import cv2\n",
    "    print('Open-CV is available, version', cv2.__version__)\n",
    "    \n",
    "except:\n",
    "     !pip install opencv-python\n",
    "    \n",
    "   \n",
    "try:\n",
    "    import seaborn\n",
    "    print('Seaborn is available, version', seaborn.__version__)\n",
    "    \n",
    "except:\n",
    "     !pip install seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy Version:  1.19.1\n",
      "Working Directory: \n",
      "  C:\\Users\\Administrator\\Desktop\\VOR\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "# Basics:\n",
    "import numpy as np,pandas as pd, matplotlib.pyplot as plt, seaborn as sns\n",
    "import os, random, time, sys, copy, math, pickle\n",
    "\n",
    "# interactive mode\n",
    "plt.ion()\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For plotting\n",
    "import plotly.io as plt_io\n",
    "import plotly.graph_objects as go\n",
    "%matplotlib inline\n",
    "\n",
    "# Dimension Reduction Algorithms:\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.decomposition import NMF\n",
    "import umap\n",
    "\n",
    "# Transformations\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Metrics:\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Train-Test Splitter:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For Classical ML algorithms:\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "# Utilies:\n",
    "from tqdm import tqdm\n",
    "\n",
    "# For distance measurements:\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Extras:\n",
    "from abc import abstractmethod\n",
    "from typing import Callable, Iterable, List, Tuple\n",
    "\n",
    "# Set true for Google Colab:\n",
    "COLAB = False\n",
    "\n",
    "if COLAB:\n",
    "    # To access Google Drive:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/gdrive\")\n",
    "\n",
    "    \n",
    "# For neuroimaging:\n",
    "from nibabel.testing import data_path\n",
    "from nilearn import plotting as nplt\n",
    "from nilearn.input_data import NiftiMasker\n",
    "from nilearn import datasets\n",
    "from nilearn import plotting\n",
    "from nilearn.image import mean_img\n",
    "from nilearn.image import index_img\n",
    "import nibabel as nib\n",
    "from nilearn import image\n",
    "\n",
    "\n",
    "\n",
    "print(\"NumPy Version: \", np.__version__)\n",
    "\n",
    "root_dir = r'C:\\Users\\Administrator\\Desktop\\VOR'\n",
    "os.chdir(root_dir)\n",
    "image_results_dir = os.path.join(root_dir, 'images')\n",
    "results_dir = os.path.join(root_dir, 'results')\n",
    "\n",
    "print('Working Directory: \\n ', root_dir)\n",
    "\n",
    "\n",
    "# Creating requirements.txt file\n",
    "!pip3 freeze > requirements.txt  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2d(component1:np.ndarray, component2:np.ndarray,path:str, y = None, ) -> None:\n",
    "    \n",
    "    fig = go.Figure(data=go.Scatter(\n",
    "        x = component1,\n",
    "        y = component2,\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=20,\n",
    "            color=y, #set color equal to a variable\n",
    "            colorscale='Rainbow', # one of plotly colorscales\n",
    "            showscale=True,\n",
    "            line_width=1\n",
    "        )\n",
    "    ))\n",
    "    fig.update_layout(margin=dict(l=100,r=100,b=100,t=100),width=2000,height=1200)                 \n",
    "    fig.layout.template = 'plotly_dark'\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    \n",
    "    fig.write_image(path)\n",
    "    \n",
    "def plot_3d(component1 : np.ndarray,\n",
    "            component2 : np.ndarray,\n",
    "            component3 :np.ndarray,\n",
    "            path:str,\n",
    "            y = None) -> None:\n",
    "    \n",
    "    fig = go.Figure(data=[go.Scatter3d(\n",
    "            x=component1,\n",
    "            y=component2,\n",
    "            z=component3,\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=10,\n",
    "                color=y,                # set color to an array/list of desired values\n",
    "                colorscale='Rainbow',   # choose a colorscale\n",
    "                opacity=1,\n",
    "                line_width=1\n",
    "            )\n",
    "        )])\n",
    "    # tight layout\n",
    "    fig.update_layout(margin=dict(l=50,r=50,b=50,t=50),width=1800,height=1000)\n",
    "    fig.layout.template = 'plotly_dark'\n",
    "\n",
    "    fig.show()\n",
    "    fig.write_image(path)\n",
    "\n",
    "def save_obj(obj:object, path:str = None) -> None:\n",
    "    with open(path + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        \n",
    "def load_obj(path:str = None) -> object:\n",
    "    with open(path + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Loading:\n",
    "fmri_imgs_mat, masks, categories = load('fMRI_data'), load('masked_data'), load('labels')\n",
    "\n",
    "subject_id = 5\n",
    "x = masks[subject_id]\n",
    "pca = PCA(n_components=3)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "\n",
    "principal = pd.DataFrame(data = principalComponents\n",
    "             ,columns = ['principal component 1',\n",
    "                         'principal component 2',\n",
    "                         'principal component 3'])\n",
    "\n",
    "plot_2d(principalComponents[:, 0],\n",
    "        principalComponents[:, 1],\n",
    "        y = categories[subject_id],\n",
    "        path = os.path.join(explanatory_fMRI_dir, 'pca_2d.png')\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d(principalComponents[:, 0],\n",
    "        principalComponents[:, 1],\n",
    "        principalComponents[:, 2],\n",
    "        path = os.path.join(explanatory_fMRI_dir, 'pca_3d.png'),\n",
    "        y = categories[subject_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-Stochastic Neighboor Embedding (t-SNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "x = masks[subject_id]\n",
    "\n",
    "tsne = TSNE(random_state = 42,\n",
    "            n_components=3,\n",
    "            verbose=0,\n",
    "            perplexity=40,\n",
    "            n_iter=400).fit_transform(x)\n",
    "\n",
    "plot_2d(tsne[:, 0],\n",
    "        tsne[:, 1],\n",
    "        path = os.path.join(explanatory_fMRI_dir, 'tsene_2d.png'),\n",
    "        y = categories[subject_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d(tsne[:, 0],\n",
    "        tsne[:, 1],\n",
    "        tsne[:, 2],\n",
    "        path = os.path.join(explanatory_fMRI_dir, 'tsene_3d.png'),\n",
    "        y = categories[subject_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Discriminate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "x = masks[subject_id]\n",
    "y = categories[subject_id]\n",
    "\n",
    "X_LDA = LDA(n_components=3).fit_transform(x,y)\n",
    "\n",
    "plot_3d(X_LDA[:, 0],\n",
    "        X_LDA[:, 1],\n",
    "        X_LDA[:, 2],\n",
    "        path = os.path.join(explanatory_fMRI_dir, 'lda_3d.png'),\n",
    "        y = categories[subject_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uniform Manifold Approximation and Projection (UMAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#!pip uninstall umap\n",
    "#!pip install umap-learn\n",
    "\n",
    "import umap.umap_ as umap\n",
    "\n",
    "reducer = umap.UMAP(random_state=42,n_components=3)\n",
    "embedding = reducer.fit_transform(x)\n",
    "\n",
    "\n",
    "plot_3d(embedding[:, 0],\n",
    "        embedding[:, 1],\n",
    "        embedding[:, 2],\n",
    "         path = os.path.join(explanatory_fMRI_dir, 'umap_3d.png'),\n",
    "        y = categories[subject_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independent Component Analysis (ICA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "fast_ica = FastICA(n_components = 3)\n",
    "ICs = fast_ica.fit_transform(x)\n",
    "\n",
    "\n",
    "plot_3d(ICs[:, 0],\n",
    "        ICs[:, 1],\n",
    "        ICs[:, 2],\n",
    "        path = os.path.join(explanatory_fMRI_dir, 'ica_3d.png'),\n",
    "        y = categories[subject_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ISOMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import Isomap\n",
    "x = masks[subject_id]\n",
    "\n",
    "embedding = Isomap(n_components=3)\n",
    "manifold = embedding.fit_transform(x)\n",
    "\n",
    "\n",
    "plot_3d(manifold[:, 0],\n",
    "        manifold[:, 1],\n",
    "        manifold[:, 2],\n",
    "        path = os.path.join(explanatory_fMRI_dir, 'isomap_3d.png'),\n",
    "        y = categories[subject_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   Locally Linear Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "\n",
    "\n",
    "embedding = LocallyLinearEmbedding(n_components=3)\n",
    "manifold = embedding.fit_transform(x,categories[subject_id])\n",
    "\n",
    "\n",
    "plot_3d(manifold[:, 0],\n",
    "        manifold[:, 1],\n",
    "        manifold[:, 2],\n",
    "        path = os.path.join(explanatory_fMRI_dir, 'lle_3d.png'),\n",
    "        y = categories[subject_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multidimensional scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "\n",
    "\n",
    "embedding = MDS(n_components=3)\n",
    "manifold = embedding.fit_transform(x,categories[subject_id])\n",
    "\n",
    "\n",
    "plot_3d(manifold[:, 0],\n",
    "        manifold[:, 1],\n",
    "        manifold[:, 2],\n",
    "        path = os.path.join(explanatory_fMRI_dir, 'mds_3d.png'),\n",
    "        y = categories[subject_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral Embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import SpectralEmbedding\n",
    "\n",
    "\n",
    "embedding = SpectralEmbedding(n_components=3)\n",
    "manifold = embedding.fit_transform(x)\n",
    "\n",
    "\n",
    "plot_3d(manifold[:, 0],\n",
    "        manifold[:, 1],\n",
    "        manifold[:, 2],\n",
    "        path = os.path.join(explanatory_fMRI_dir, 'SpectralEmbedding_3d.png'),\n",
    "        y = categories[subject_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
