{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                               - Computational Neuroscience 2021-2022 Final Project -                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functional architecture of the object vision pathway in the human brain was\n",
    "investigated using functional magnetic resonance imaging to measure patterns\n",
    "of response in ventral temporal cortex while subjects viewed faces, cats, Þve\n",
    "categories of man-made objects, and nonsense pictures. A distinct pattern of\n",
    "response was found for each stimulus category. The distinctiveness of the\n",
    "response to a given category was not due simply to the regions that responded\n",
    "maximally to that category, because the category being viewed also could be\n",
    "identiÞed on the basis of the pattern of response when those regions were\n",
    "excluded from the analysis. Patterns of response that discriminated among all\n",
    "categories were found even within cortical regions that responded maximally\n",
    "to only one category. These results indicate that the representations of faces\n",
    "and objects in ventral temporal cortex are widely distributed and overlapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Filename       : CompNeuro_2021-2022_Final_Project.ipynb\n",
    "\n",
    "Authors        : Arman Vural Budunoğlu and Can Kocagil\n",
    "\n",
    "Institution    : Bilkent University Departman of Electric & Electronical Enginering\n",
    "\n",
    "Class          : EEE482/582 - Computational Neuroscience \n",
    "\n",
    "Project Goal   : Implement multi-voxel pattern analyses methods (based on some type of classifier) to\n",
    "                 decode the category of visual stimuli viewed by a human subject based on their recorded brain activity\n",
    "                 \n",
    "Dataset Link   : https://openfmri.org/dataset/ds000105.\n",
    "\n",
    "Related Papers : Distributed and overlapping representations of faces and objects in ventral temporal cortex\n",
    "\n",
    "Abstract:\n",
    "\n",
    "    The functional architecture of the object vision pathway in the human brain was\n",
    "    investigated using functional magnetic resonance imaging to measure patterns\n",
    "    of response in ventral temporal cortex while subjects viewed faces, cats, Þve\n",
    "    categories of man-made objects, and nonsense pictures. A distinct pattern of\n",
    "    response was found for each stimulus category. The distinctiveness of the\n",
    "    response to a given category was not due simply to the regions that responded\n",
    "    maximally to that category, because the category being viewed also could be\n",
    "    identiÞed on the basis of the pattern of response when those regions were\n",
    "    excluded from the analysis. Patterns of response that discriminated among all\n",
    "    categories were found even within cortical regions that responded maximally\n",
    "    to only one category. These results indicate that the representations of faces\n",
    "    and objects in ventral temporal cortex are widely distributed and overlapping.\n",
    "\n",
    "Pipeline:\n",
    "    \n",
    "    1) Necessary Installations (If necessary)\n",
    "    2) Imports\n",
    "    3) Visual Stimuli and Category Loading\n",
    "    4) Visual Stimuli Transformations\n",
    "    5) Explanatory Visual Stimuli Analysis\n",
    "        \n",
    "        * PCA\n",
    "        * T-Stochastic Neighboor Embedding (t-SNE)\n",
    "        * Linear Discriminate Analysis\n",
    "        * Uniform Manifold Approximation and Projection (UMAP)\n",
    "        * Independent Component Analysis (ICA)\n",
    "        * Non-Negative Matrix Factorization\n",
    "        * Masking\n",
    "        \n",
    "    6) Visual Stimuli Similarity Analysis\n",
    "    \n",
    "        * Euclidean Similarity\n",
    "        * Cosine Similarity\n",
    "        * Pearson Correlation             \n",
    "        \n",
    "    7) Classical ML Algorithms:\n",
    "    \n",
    "        * LinearSVC\n",
    "        * SGDClassifier\n",
    "        * MLPClassifier\n",
    "        * Perceptron\n",
    "        * LogisticRegression\n",
    "        * LogisticRegressionCV\n",
    "        * SVC\n",
    "        * CalibratedClassifierCV\n",
    "        * PassiveAggressiveClassifier\n",
    "        * LabelPropagation\n",
    "        * LabelSpreading\n",
    "        * RandomForestClassifier\n",
    "        * GradientBoostingClassifier\n",
    "        * QuadraticDiscriminantAnalysis\n",
    "        * RidgeClassifierCV\n",
    "        * RidgeClassifier\n",
    "        * AdaBoostClassifier\n",
    "        * ExtraTreesClassifier\n",
    "        * KNeighborsClassifier\n",
    "        * BaggingClassifier\n",
    "        * BernoulliNB\n",
    "        * LinearDiscriminantAnalysis\n",
    "        * GaussianNB\n",
    "        * NuSVC\n",
    "        * DecisionTreeClassifier\n",
    "        * NearestCentroid\n",
    "        * ExtraTreeClassifier\n",
    "        * CheckingClassifier\n",
    "        * DummyClassifier\n",
    "        \n",
    "    7) Reported Metrics\n",
    "        * Accuracy\n",
    "        * Balanced Accuracy\n",
    "        * ROC AUC\n",
    "        * F1-Score\n",
    "        * Time Taken\n",
    "        \n",
    "    8) Deep Learning Algorithms\n",
    "        * 3-D Convolutional Neural Networks\n",
    "        * Visual Transformers\n",
    "        * ...\n",
    "        \n",
    "    9) Results Interpretation\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Necessary Installations (If necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: umap in d:\\python\\lib\\site-packages (0.1.1)\n",
      "Requirement already satisfied: pipreqs in d:\\python\\lib\\site-packages (0.4.10)\n",
      "Requirement already satisfied: docopt in d:\\python\\lib\\site-packages (from pipreqs) (0.6.2)\n",
      "Requirement already satisfied: yarg in d:\\python\\lib\\site-packages (from pipreqs) (0.1.9)\n",
      "Requirement already satisfied: requests in d:\\python\\lib\\site-packages (from yarg->pipreqs) (2.24.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in d:\\python\\lib\\site-packages (from requests->yarg->pipreqs) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\python\\lib\\site-packages (from requests->yarg->pipreqs) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in d:\\python\\lib\\site-packages (from requests->yarg->pipreqs) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\python\\lib\\site-packages (from requests->yarg->pipreqs) (2.10)\n",
      "Requirement already satisfied: lazypredict in d:\\python\\lib\\site-packages (0.2.9)\n",
      "Requirement already satisfied: six==1.15.0 in d:\\python\\lib\\site-packages (from lazypredict) (1.15.0)\n",
      "Requirement already satisfied: joblib==1.0.0 in d:\\python\\lib\\site-packages (from lazypredict) (1.0.0)\n",
      "Requirement already satisfied: scipy==1.5.4 in d:\\python\\lib\\site-packages (from lazypredict) (1.5.4)\n",
      "Requirement already satisfied: tqdm==4.56.0 in d:\\python\\lib\\site-packages (from lazypredict) (4.56.0)\n",
      "Requirement already satisfied: scikit-learn==0.23.1 in d:\\python\\lib\\site-packages (from lazypredict) (0.23.1)\n",
      "Requirement already satisfied: xgboost==1.1.1 in d:\\python\\lib\\site-packages (from lazypredict) (1.1.1)\n",
      "Requirement already satisfied: click==7.1.2 in d:\\python\\lib\\site-packages (from lazypredict) (7.1.2)\n",
      "Requirement already satisfied: lightgbm==2.3.1 in d:\\python\\lib\\site-packages (from lazypredict) (2.3.1)\n",
      "Requirement already satisfied: PyYAML==5.3.1 in d:\\python\\lib\\site-packages (from lazypredict) (5.3.1)\n",
      "Requirement already satisfied: pandas==1.0.5 in d:\\python\\lib\\site-packages (from lazypredict) (1.0.5)\n",
      "Requirement already satisfied: numpy==1.19.1 in d:\\python\\lib\\site-packages (from lazypredict) (1.19.1)\n",
      "Requirement already satisfied: pytest==5.4.3 in d:\\python\\lib\\site-packages (from lazypredict) (5.4.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\python\\lib\\site-packages (from scikit-learn==0.23.1->lazypredict) (2.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in d:\\python\\lib\\site-packages (from pandas==1.0.5->lazypredict) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in d:\\python\\lib\\site-packages (from pandas==1.0.5->lazypredict) (2020.1)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in d:\\python\\lib\\site-packages (from pytest==5.4.3->lazypredict) (8.6.0)\n",
      "Requirement already satisfied: wcwidth in d:\\python\\lib\\site-packages (from pytest==5.4.3->lazypredict) (0.2.5)\n",
      "Requirement already satisfied: packaging in d:\\python\\lib\\site-packages (from pytest==5.4.3->lazypredict) (20.4)\n",
      "Requirement already satisfied: py>=1.5.0 in d:\\python\\lib\\site-packages (from pytest==5.4.3->lazypredict) (1.9.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0; sys_platform == \"win32\" in d:\\python\\lib\\site-packages (from pytest==5.4.3->lazypredict) (1.4.0)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in d:\\python\\lib\\site-packages (from pytest==5.4.3->lazypredict) (0.13.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in d:\\python\\lib\\site-packages (from pytest==5.4.3->lazypredict) (20.3.0)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in d:\\python\\lib\\site-packages (from pytest==5.4.3->lazypredict) (0.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in d:\\python\\lib\\site-packages (from packaging->pytest==5.4.3->lazypredict) (2.4.7)\n",
      "Requirement already satisfied: nibabel in d:\\python\\lib\\site-packages (3.2.1)\n",
      "Requirement already satisfied: numpy>=1.14 in d:\\python\\lib\\site-packages (from nibabel) (1.19.1)\n",
      "Requirement already satisfied: packaging>=14.3 in d:\\python\\lib\\site-packages (from nibabel) (20.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in d:\\python\\lib\\site-packages (from packaging>=14.3->nibabel) (2.4.7)\n",
      "Requirement already satisfied: six in d:\\python\\lib\\site-packages (from packaging>=14.3->nibabel) (1.15.0)\n",
      "Requirement already satisfied: nilearn in d:\\python\\lib\\site-packages (0.7.1)\n",
      "Requirement already satisfied: requests>=2 in d:\\python\\lib\\site-packages (from nilearn) (2.24.0)\n",
      "Requirement already satisfied: pandas>=0.18.0 in d:\\python\\lib\\site-packages (from nilearn) (1.0.5)\n",
      "Requirement already satisfied: joblib>=0.12 in d:\\python\\lib\\site-packages (from nilearn) (1.0.0)\n",
      "Requirement already satisfied: scikit-learn>=0.19 in d:\\python\\lib\\site-packages (from nilearn) (0.23.1)\n",
      "Requirement already satisfied: scipy>=0.19 in d:\\python\\lib\\site-packages (from nilearn) (1.5.4)\n",
      "Requirement already satisfied: numpy>=1.11 in d:\\python\\lib\\site-packages (from nilearn) (1.19.1)\n",
      "Requirement already satisfied: nibabel>=2.0.2 in d:\\python\\lib\\site-packages (from nilearn) (3.2.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\python\\lib\\site-packages (from requests>=2->nilearn) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\python\\lib\\site-packages (from requests>=2->nilearn) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in d:\\python\\lib\\site-packages (from requests>=2->nilearn) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in d:\\python\\lib\\site-packages (from requests>=2->nilearn) (1.25.11)\n",
      "Requirement already satisfied: pytz>=2017.2 in d:\\python\\lib\\site-packages (from pandas>=0.18.0->nilearn) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in d:\\python\\lib\\site-packages (from pandas>=0.18.0->nilearn) (2.8.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\python\\lib\\site-packages (from scikit-learn>=0.19->nilearn) (2.1.0)\n",
      "Requirement already satisfied: packaging>=14.3 in d:\\python\\lib\\site-packages (from nibabel>=2.0.2->nilearn) (20.4)\n",
      "Requirement already satisfied: six>=1.5 in d:\\python\\lib\\site-packages (from python-dateutil>=2.6.1->pandas>=0.18.0->nilearn) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in d:\\python\\lib\\site-packages (from packaging>=14.3->nibabel>=2.0.2->nilearn) (2.4.7)\n",
      "Scikit-learn is available, version 0.23.1\n",
      "Open-CV is available, version 4.5.1\n",
      "Seaborn is available, version 0.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install umap\n",
    "!pip install pipreqs\n",
    "!pip install lazypredict\n",
    "!pip install nibabel\n",
    "!pip install nilearn\n",
    "\n",
    "try:\n",
    "    import sklearn\n",
    "    print('Scikit-learn is available, version', sklearn.__version__)\n",
    "    \n",
    "except:\n",
    "    !pip install scikit-learn\n",
    "    \n",
    " \n",
    "try:\n",
    "    import cv2\n",
    "    print('Open-CV is available, version', cv2.__version__)\n",
    "    \n",
    "except:\n",
    "     !pip install opencv-python\n",
    "    \n",
    "   \n",
    "try:\n",
    "    import seaborn\n",
    "    print('Seaborn is available, version', seaborn.__version__)\n",
    "    \n",
    "except:\n",
    "     !pip install seaborn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy Version:  1.19.1\n",
      "Working Directory: \n",
      "  C:\\Users\\Administrator\\Desktop\\VOR\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "# Basics:\n",
    "import numpy as np,pandas as pd, matplotlib.pyplot as plt, seaborn as sns\n",
    "import os, random, time, sys, cv2, copy, math\n",
    "\n",
    "\n",
    "# interactive mode\n",
    "plt.ion()\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For plotting\n",
    "import plotly.io as plt_io\n",
    "import plotly.graph_objects as go\n",
    "%matplotlib inline\n",
    "\n",
    "# Dimension Reduction Algorithms:\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.decomposition import NMF\n",
    "import umap\n",
    "\n",
    "# Transformations\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Metrics:\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Train-Test Splitter:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For Classical ML algorithms:\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "# Utilies:\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "# For distance measurements:\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Extras:\n",
    "from abc import abstractmethod\n",
    "from typing import Callable, Iterable, List\n",
    "\n",
    "# Set true for Google Colab:\n",
    "COLAB = False\n",
    "\n",
    "if COLAB:\n",
    "    # To access Google Drive:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/gdrive\")\n",
    "\n",
    "    \n",
    "# For neuroimaging:\n",
    "from nibabel.testing import data_path\n",
    "from nilearn import plotting as nplt\n",
    "from nilearn.input_data import NiftiMasker\n",
    "    \n",
    "\n",
    "\n",
    "print(\"NumPy Version: \", np.__version__)\n",
    "\n",
    "\n",
    "root_dir = os.getcwd()\n",
    "dataset_dir = os.path.join(root_dir,'dataset')\n",
    "\n",
    "print('Working Directory: \\n ', root_dir)\n",
    "\n",
    "\n",
    "# Creating requirements.txt file\n",
    "!pip3 freeze > requirements.txt  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(labels:Iterable[list or np.ndarray],\n",
    "                     preds:Iterable[list or np.ndarray]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "        Takes desireds/labels and softmax predictions,\n",
    "        return a confusion matrix.\n",
    "        \n",
    "    \"\"\"\n",
    "    label = pd.Series(labels,name='Actual')\n",
    "    pred = pd.Series(preds,name='Predicted')\n",
    "    return pd.crosstab(label,pred)\n",
    "\n",
    "def visualize_confusion_matrix(data:np.ndarray,\n",
    "                               normalize:bool = True,\n",
    "                               title:str = \" \") -> None:\n",
    "    \n",
    "    if normalize:\n",
    "\n",
    "        data /= np.sum(data)\n",
    "\n",
    "    plt.figure(figsize=(15,15))\n",
    "    sns.heatmap(data, \n",
    "                fmt='.2%',\n",
    "                cmap = 'Greens')\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def accuracy(labels,preds):\n",
    "      return (np.sum(preds == labels) / labels.shape) * 100\n",
    "\n",
    "\n",
    "def save_obj(obj:object, path:str = None) -> None:\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        \n",
    "def load_obj(path:str = None) -> object:\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "def save(data:np.ndarray = None,path:str = None) -> None:\n",
    "    np.save(path + '.npy', data)\n",
    "\n",
    "\n",
    "def load(path:str = None) -> np.ndarray:\n",
    "    return np.load(path + '.npy')    \n",
    "    \n",
    "    \n",
    "def random_seed(Func:Callable):\n",
    "    def _random_seed(*args, **kwargs):\n",
    "        np.random.seed(42)\n",
    "        random.seed(42)\n",
    "        result = Func(*args, **kwargs)\n",
    "        return result\n",
    "    return _random_seed\n",
    "\n",
    "\n",
    "@random_seed \n",
    "def timeit(Func:Callable):\n",
    "    def _timeStamp(*args, **kwargs):\n",
    "        since = time.time()\n",
    "        result = Func(*args, **kwargs)\n",
    "        time_elapsed = time.time() - since\n",
    "\n",
    "        if time_elapsed > 60:\n",
    "           print('Time Consumed : {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))  \n",
    "        else:        \n",
    "          print('Time Consumed : ' , round((time_elapsed),4) , 's')\n",
    "        return result\n",
    "    return _timeStamp\n",
    "\n",
    "@random_seed \n",
    "@timeit\n",
    "def plot_2d(component1:np.ndarray, component2:np.ndarray, y = None) -> None:\n",
    "    \n",
    "    fig = go.Figure(data=go.Scatter(\n",
    "        x = component1,\n",
    "        y = component2,\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=20,\n",
    "            color=y, #set color equal to a variable\n",
    "            colorscale='Rainbow', # one of plotly colorscales\n",
    "            showscale=True,\n",
    "            line_width=1\n",
    "        )\n",
    "    ))\n",
    "    fig.update_layout(margin=dict( l=100,r=100,b=100,t=100),width=2000,height=1200)                 \n",
    "    fig.layout.template = 'plotly_dark'\n",
    "    \n",
    "    fig.show()\n",
    " \n",
    "@random_seed \n",
    "@timeit\n",
    "def plot_3d(component1: np.ndarray,component2 : np.ndarray,component3 :np.ndarray, y = None) -> None:\n",
    "    fig = go.Figure(data=[go.Scatter3d(\n",
    "            x=component1,\n",
    "            y=component2,\n",
    "            z=component3,\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=10,\n",
    "                color=y,                # set color to an array/list of desired values\n",
    "                colorscale='Rainbow',   # choose a colorscale\n",
    "                opacity=1,\n",
    "                line_width=1\n",
    "            )\n",
    "        )])\n",
    "    # tight layout\n",
    "    fig.update_layout(margin=dict(l=50,r=50,b=50,t=50),width=1800,height=1000)\n",
    "    fig.layout.template = 'plotly_dark'\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Stimuli and Category Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: %%time is a cell magic, but the cell body is empty. Did you mean the line magic %time (single %)?\n"
     ]
    }
   ],
   "source": [
    "%%time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Visual Stimuli Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Standardizing the data\n",
    "# x = StandardScaler().fit_transform(x)\n",
    "\n",
    "# Normalizing data:\n",
    "# MinMaxScaler().fit_transform(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanatory Visual Stimuli Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principal = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2','principal component 3'])\n",
    "\n",
    "#plot_2d(principalComponents[:, 0],principalComponents[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-Stochastic Neighboor Embedding (t-SNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "pca_50 = PCA(n_components=50)\n",
    "pca_result_50 = pca_50.fit_transform(x)\n",
    "tsne = TSNE(random_state = 42, n_components=3,verbose=0, perplexity=40, n_iter=400).fit_transform(pca_result_50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Discriminate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "X_LDA = LDA(n_components=3).fit_transform(standardized_data,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uniform Manifold Approximation and Projection (UMAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "reducer = umap.UMAP(random_state=42,n_components=3)\n",
    "embedding = reducer.fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independent Component Analysis (ICA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "fast_ica = FastICA(n_components = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Negative Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "nmf = NMF(n_components = 3, max_iter=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical ML Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "# models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# PyTorch's versions:\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "\n",
    "# We will be working with GPU:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device : ' , device)\n",
    "\n",
    "# Number of GPUs available. \n",
    "num_GPU = torch.cuda.device_count()\n",
    "print('Number of GPU : ', num_GPU)\n",
    "\n",
    "config = {'batch_size': 4}\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                                transforms.ColorJitter([0.9,0.9]),\n",
    "                                transforms.RandomGrayscale(p = 0.3),\n",
    "                                transforms.RandomAffine((-30,30)),\n",
    "                                transforms.RandomPerspective(),\n",
    "                                transforms.GaussianBlur(3),\n",
    "                                transforms.RandomHorizontalFlip(p = 0.2),\n",
    "                                transforms.RandomVerticalFlip(p = 0.2),\n",
    "\n",
    "                                # Important parts, above can be ignored\n",
    "                                transforms.Resize((224,224))),\n",
    "                                transforms.CenterCrop(224),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean = (0.5,0.5,0.5),\n",
    "                                                     std  = (0.5,0.5,0.5))       \n",
    "                                \n",
    "]))\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset = CelebrityData,\n",
    "                                         shuffle = True,\n",
    "                                         batch_size = config['batch_size'],\n",
    "                                         num_workers = num_GPU * 4,\n",
    "                                         drop_last = True,\n",
    "                                         pin_memory = True)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(inputs):\n",
    "    \n",
    "      outputs = model(inputs)\n",
    "      _, preds = torch.max(outputs, 1)  \n",
    "      return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-D Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self,model = None):\n",
    "        super(Model,self).__init__()\n",
    "        if model is not None:\n",
    "            self.model = model    \n",
    "        else:\n",
    "            self.model = nn.Sequential(\n",
    "            self.conv_block(3,32,0.1),\n",
    "            self.conv_block(32,64,0.15),\n",
    "            self.conv_block(64,128,0.2),\n",
    "            self.conv_block(128,256,0.25),\n",
    "            self.conv_block(256,512,0.3),\n",
    "            self.conv_block(512,1024,0.35),\n",
    "            nn.Flatten(),\n",
    "            self.linear_block(1024,512,0.4),\n",
    "            self.linear_block(512,256,0.4),\n",
    "            nn.Linear(256,136)\n",
    "            )     \n",
    "\n",
    "    def forward(self,img):    \n",
    "        return self.model(img)  \n",
    "\n",
    "    @staticmethod\n",
    "    def conv_block(in_channel,out_channel,p):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channel, out_channel, 3),\n",
    "            nn.BatchNorm2d(out_channel),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Dropout2d(p)\n",
    "            )\n",
    "\n",
    "    @staticmethod\n",
    "    def linear_block(in_ftrs,out_ftrs,p):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(in_ftrs,out_ftrs),\n",
    "            nn.BatchNorm1d(num_features=out_ftrs),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p)\n",
    "            )\n",
    "\n",
    "net = Model().to(device)\n",
    "\n",
    "\n",
    "print('Traniable parameter of the model: ' , sum(param.numel() for param in net.parameters() if param.requires_grad == True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environmental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
